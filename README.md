# BanglaLLama-3.2-3B-Instuct-QA
BanglaLLama-3.2-3B-Instruct-QA

Base Paper Link:
https://www.tandfonline.com/doi/full/10.1080/24751839.2020.1833136

Dataset link:
https://www.kaggle.com/datasets/mayeesha/bengali-question-answering-dataset/data

HF Dataset Repo:
https://huggingface.co/datasets/Kowshik24/BengaliQADataset

HF Model Repo:
https://huggingface.co/Kowshik24/Bangla-llama-3.2-3B-Instruct-QA-v2

Base Model:
https://huggingface.co/unsloth/Llama-3.2-3B-Instruct

Step	Training Loss
1	1.346200
2	1.742600
3	1.333100
4	1.845000
5	1.219900
6	1.122700
7	0.542400
8	1.124000
9	0.691200
10	0.573400
11	0.448500
12	0.743600
13	0.394300
14	0.382700
15	0.574600
16	0.441100
17	0.369000
18	0.551700
19	0.319200
20	0.434200
21	0.904800
22	0.522800
23	0.280700
24	0.583000
25	0.316000
26	0.197200
27	0.395800
28	0.201600
29	0.438500
30	0.346500
31	0.928400
32	0.529600
33	0.323300
34	0.180300
35	0.401200
36	0.335500
37	0.217700
38	0.742200
39	0.369900
40	0.373000
41	0.348200
42	0.270800
43	0.217600
44	0.474700
45	0.328500
46	0.341300
47	0.453200
48	0.419200
49	0.443300
50	0.392000
51	0.463400
52	0.169300
53	0.415900
54	0.141000
55	0.289300
56	0.274800
57	0.286500
58	0.254900
59	0.303100
60	0.261400


TrainOutput(global_step=60, training_loss=0.5222683399915695, metrics={'train_runtime': 326.8495, 'train_samples_per_second': 1.469, 'train_steps_per_second': 0.184, 'total_flos': 1.133758247061504e+16, 'train_loss': 0.5222683399915695, 'epoch': 0.014145105204219957})


Exact Match: 14.22%
F1 Score: 38.63%



