{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Gy6O7MS_sA9R"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Ds5IGIutsElu",
    "outputId": "fd4c9ffe-646c-4e67-ff72-4eeef9ad398d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu121'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwaiMMfJsGE7",
    "outputId": "88991a6d-0dab-4b29-8e22-3bea12a5552f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 29 23:53:23 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000               On  | 00000000:00:09.0 Off |                  Off |\n",
      "| 41%   33C    P8              14W / 140W |   7527MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvwQbnDnsJnN"
   },
   "source": [
    "# Install Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ixtkqKFsHbU",
    "outputId": "2fe5c3d0-cb5a-44d3-a536-15a4f172601f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /usr/local/lib/python3.10/dist-packages (2024.9.post3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Found existing installation: unsloth 2024.9.post3\n",
      "Uninstalling unsloth-2024.9.post3:\n",
      "  Successfully uninstalled unsloth-2024.9.post3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-6kovxbwc/unsloth_728755e88bc246d984321dbc9153a33c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-6kovxbwc/unsloth_728755e88bc246d984321dbc9153a33c\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit c3f4e9a87d964ecee1efd9963f497119edbefaab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.11)\n",
      "Requirement already satisfied: transformers>=4.45.1 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.45.1)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.24.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.25.1)\n",
      "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.1->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.8.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.9.post3-py3-none-any.whl size=164819 sha256=77df3493d3ac2dd3262629ee69ebced566104d21a61280d5c5bdbd98dcfc3b46\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-txo7hw9q/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth\n",
      "Successfully installed unsloth-2024.9.post3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J0wnE0hksMK0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naTJ1Bh6sRx0",
    "outputId": "cba4f08e-3a2a-469d-8a41-bebd706c9ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.9.post3: Fast Llama patching. Transformers = 4.45.1.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A4000. Max memory: 15.731 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8f810abad64fd3a5ea508e0d9f7ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  82%|########2 | 4.70G/5.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811ad38fa1da4432a43e492260cf4115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8551a62b754475a8451b7d8fa7c430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e76195e719541b2ac640d058a3b67b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a8e5c6a88544b18760ae9d5cbc1fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uUBoizk3sfyz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.9.post3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n2T4xnPQs_Dj"
   },
   "outputs": [],
   "source": [
    "# Function to format the prompts based on the dataset structure\n",
    "def formatting_prompts_func(examples):\n",
    "    # Extract context, question, and answers from the examples\n",
    "    contexts = examples[\"context\"]\n",
    "    questions = examples[\"question\"]\n",
    "    answers_list = examples.get(\"answers\", [])  # Assuming 'answers' may be missing or empty\n",
    "\n",
    "    # Initialize list to store formatted conversations\n",
    "    convos = []\n",
    "\n",
    "    # Loop through each example and format into conversation structure\n",
    "    for context, question, answers in zip(contexts, questions, answers_list):\n",
    "        # Handle cases where 'answers' is missing or empty\n",
    "        if not answers:  # Skip if answers are missing or empty\n",
    "            answers = \"\"\n",
    "        elif isinstance(answers, list):\n",
    "            answers = ' '.join([ans[\"text\"] for ans in answers if \"text\" in ans])  # Adjust this to match your structure\n",
    "\n",
    "        convo = [\n",
    "            {\"content\": context, \"role\": \"system\"},  # System role is context\n",
    "            {\"content\": question, \"role\": \"user\"},   # User role is question\n",
    "        ]\n",
    "\n",
    "        # Only add assistant's response if answers exist\n",
    "        if answers:\n",
    "            convo.append({\"content\": answers, \"role\": \"assistant\"})\n",
    "\n",
    "        convos.append(convo)\n",
    "\n",
    "    # Apply chat template using tokenizer\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
    "\n",
    "    return {\"text\": texts}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Kowshik24/BengaliQADataset\", split=\"train\",token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHR6f2EJuWAl",
    "outputId": "aaa2b39f-eff2-4b21-81e6-025d41f6e1b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'question', 'id', 'answers', 'answer_start', 'context'],\n",
       "    num_rows: 33934\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f21IqXBl7LHx"
   },
   "outputs": [],
   "source": [
    "# Map function over dataset\n",
    "#formatted_dataset = dataset.map(formatting_prompts_func, batched=True, desc=\"Formatting prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcrSzWQ10rmG",
    "outputId": "b3f6b649-d996-43c0-c59a-52831d52b85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Roman_Republic', 'question': 'রোমান প্রজাতন্ত্র কখন শুরু হয়েছিল?  ', 'id': '572fb719b2c2fd14005683a7', 'answers': '৫০৯ অবধি, ', 'answer_start': 184, 'context': 'রোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।  ', 'conversations': [{'content': 'রোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।  ', 'role': 'system'}, {'content': 'রোমান প্রজাতন্ত্র কখন শুরু হয়েছিল?  ', 'role': 'user'}, {'content': '৫০৯ অবধি, ', 'role': 'assistant'}]}\n",
      "{'title': 'Roman_Republic', 'question': 'রোমান প্রজাতন্ত্র কখন শেষ হয়েছিল?  ', 'id': '572fb719b2c2fd14005683a8', 'answers': ' বিসি প', 'answer_start': 1083, 'context': 'রোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।  ', 'conversations': [{'content': 'রোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।  ', 'role': 'system'}, {'content': 'রোমান প্রজাতন্ত্র কখন শেষ হয়েছিল?  ', 'role': 'user'}, {'content': ' বিসি প', 'role': 'assistant'}]}\n",
      "{'title': 'Roman_Republic', 'question': 'রোমান প্রজাতন্ত্রের সূচনা কী?  ', 'id': '572fb719b2c2fd14005683a9', 'answers': 'রোমান রাজ্যের উত্থানের ', 'answer_start': 111, 'context': 'রোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।  ', 'conversations': [{'content': 'রোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।  ', 'role': 'system'}, {'content': 'রোমান প্রজাতন্ত্রের সূচনা কী?  ', 'role': 'user'}, {'content': 'রোমান রাজ্যের উত্থানের ', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "# Transform the dataset\n",
    "def transform_example(example):\n",
    "    transformed = {\n",
    "        \"conversations\": []  # Initialize a list to hold messages\n",
    "    }\n",
    "\n",
    "    # Add context as system role\n",
    "    transformed[\"conversations\"].append({\"content\": example['context'], \"role\": \"system\"})\n",
    "\n",
    "    # Add question as user role\n",
    "    transformed[\"conversations\"].append({\"content\": example['question'], \"role\": \"user\"})\n",
    "\n",
    "    # Add answers as assistant role only if not empty\n",
    "    if example['answers']:\n",
    "        transformed[\"conversations\"].append({\"content\": example['answers'], \"role\": \"assistant\"})\n",
    "\n",
    "    return transformed\n",
    "\n",
    "# Apply transformation to the dataset\n",
    "transformed_dataset = dataset.map(transform_example)\n",
    "\n",
    "# Print out a few examples from the transformed dataset\n",
    "for i in range(3):  # Print first 3 examples\n",
    "    print(transformed_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hf99FJoH4RQF",
    "outputId": "503d59c9-15ec-4bf6-df8f-40380e7763c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'রোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।  ',\n",
       "  'role': 'system'},\n",
       " {'content': 'রোমান প্রজাতন্ত্র কখন শুরু হয়েছিল?  ', 'role': 'user'},\n",
       " {'content': '৫০৯ অবধি, ', 'role': 'assistant'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset[0]['conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8WZ2UeK48gZ",
    "outputId": "a688bc23-6f23-41f7-b385-598bcd6f766a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33934"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f9uBJm1N57-3"
   },
   "outputs": [],
   "source": [
    "convos = transformed_dataset['conversations']\n",
    "texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
    "\n",
    "final_dataset = {\"text\": texts,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BushvbWc-RVC"
   },
   "outputs": [],
   "source": [
    "#final_dataset = [{\"text\": text} for text in texts]\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99,
     "referenced_widgets": [
      "9c62889c16864a338d1689561d41a1a3",
      "58d30f2eda5a44f8ad7e4deaae03fb07",
      "53e73fb7d3ee4e8abe14d30a8592f18c",
      "c8e44a505fa34497a9cb289c8da14b90",
      "1a83ebed2dff43359f3ee83f2cd779c5",
      "fbf2d665f79c48b3bf1e13776764d7c9",
      "87d6126facf840daaf58d8e4c36ad575",
      "7945a68885804cda87a9fd0319937f7f",
      "0c284ff2943f419eb1623787468562b0",
      "de286e54e62a45949f6b2cf8b4e659b6",
      "7b43c37118d5467dbd3e6f799af413b5",
      "4cc30070c3e84ba199cf070c518cdffa",
      "2901416e9d334ad7abc98d5c244a7dc2",
      "8e513ff19cf446eba8192f2d0b818048",
      "c02b81fd46684181bd212cf2d46e5996",
      "f75e14902a114ab288b7574155877de7",
      "3dcb4aae63be44868b3f7b59303fd010",
      "131ab9d6182842b4b87c9c0f39b51783",
      "8dd0ec32d90840718ecad72dc8b5985c",
      "470c597e44e34e86900d1e7fb95c0993",
      "cd1c18bbcd5949d89f58c88ec8b409cd",
      "41a5d13a96404f9da1cb1ff488d8be46"
     ]
    },
    "id": "3SUu6g2a4a8W",
    "outputId": "54fbf7f4-5a61-4731-9812-2c635e376ec5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9471daf544e24bc3bccfb5597735866c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33934 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ab885208b444038ff465d801b93dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/33934 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# Convert the final dataset into a Hugging Face Dataset object\n",
    "final_dataset = Dataset.from_dict({\"text\": texts})\n",
    "\n",
    "# Ensure that the 'text' field is present and accessible\n",
    "def format_for_trainer(examples):\n",
    "    return {\"text\": examples[\"text\"]}\n",
    "\n",
    "final_dataset = final_dataset.map(format_for_trainer, batched=True)\n",
    "\n",
    "# Initialize the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=final_dataset,\n",
    "    dataset_text_field=\"text\",  # Make sure this field exists\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,  # Can make training 5x faster for short sequences.\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        max_steps=60,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQJdNyBJAI8g",
    "outputId": "a7041d7c-71dc-4f9e-d443-a7a1ffe6b77c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nরোমান প্রজাতন্ত্র লাতিন: রেজ পাবলিকা রোমানা; ধ্রুপদী লাতিন: ːː ˈː.ɪ. ːˈː. ছিল প্রাচীন রোমান সভ্যতার সময়কাল যা রোমান রাজ্যের উত্থানের মধ্য দিয়ে শুরু হয়েছিল, তিহ্যগতভাবে খ্রিস্টপূর্ব ৫০৯ অবধি, এবং শেষ হয়েছিল  খ্রিস্টপূর্ব ২ ২৭ রোমান সাম্রাজ্য প্রতিষ্ঠার সাথে। এই সময়কালেই রোমের নিয়ন্ত্রণ শহরের তাত্ক্ষণিক আশেপাশের অঞ্চল থেকে সমগ্র ভূমধ্যসাগরীয় অঞ্চলে আধিপত্য বিস্তার করে। এর অস্তিত্বের প্রথম দুটি শতাব্দীতে রোমান প্রজাতন্ত্রের বিজয় এবং জোটের সংমিশ্রণের মধ্য দিয়ে মধ্য ইতালি থেকে পুরো ইতালীয় উপদ্বীপে প্রসারিত হয়েছিল। পরবর্তী শতাব্দীর মধ্যে এটি উত্তর আফ্রিকা, স্পেন এবং বর্তমানে দক্ষিণ ফ্রান্স যা অন্তর্ভুক্ত করেছিল। এর দুই শতাব্দী পরে, খ্রিস্টপূর্ব প্রথম শতাব্দীর শেষের দিকে, এর মধ্যে আধুনিক ফ্রান্স, গ্রিস এবং পূর্ব ভূমধ্যসাগরীয় অংশের বেশিরভাগ অংশ অন্তর্ভুক্ত ছিল। এই সময়ের মধ্যে, অভ্যন্তরীণ উত্তেজনা একের পর এক গৃহযুদ্ধের দিকে পরিচালিত করেছিল, যার পরিণতি জুলিয়াস সিজারের হত্যার সাথে ঘটেছিল, যা প্রজাতন্ত্র থেকে সাম্রাজ্যের দিকে উত্তরণের দিকে পরিচালিত করেছিল। পরিবর্তনের সঠিক তারিখ ব্যাখ্যার বিষয় হতে পারে। তিহাসিকরা বিভিন্নভাবে জুলাইস সিজারের রুবিকান নদী পার হওয়ার ৪৯ বিসি পূর্বে প্রস্তাব করেছিলেন, খৃস্টপূর্ব ৪৪ খ্রিস্টাব্দে সিজারের আজীবন একনায়ক হিসাবে নিয়োগ এবং খ্রিস্টপূর্ব ৩১ খ্রিস্টাব্দে অ্যাকটিয়ামের যুদ্ধে মার্ক অ্যান্টনি এবং ক্লিওপেট্রার পরাজয়ের প্রস্তাব। তবে, বেশিরভাগ একই তারিখটি প্রাচীন রোমানরা যেমন করেছিলেন তেমনি ব্যবহার করেছেন, রোমান সিনেটের অক্টাভিয়ানকে অসাধারণ ক্ষমতা প্রদান এবং তিনি ২  খ্রিস্টপূর্বাব্দে অগাস্টাস উপাধি গ্রহণ করেছিলেন, এটি প্রজাতন্ত্রের সমাপ্তির সংজ্ঞা হিসাবে সংঘটিত ঘটনা।<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nরোমান প্রজাতন্ত্র কখন শুরু হয়েছিল?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n৫০৯ অবধি,<|eot_id|>'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d93543ad8e2f46409e452556e5dfc1b2",
      "b79fa1195b45447f94c97b151b2f8df1",
      "d57a0987bdd94067b85d32feaed7902c",
      "55f8d3afa5c74ce0aa1a3b2d331123b7",
      "7cdcb2f62d1046aba0d4faa537cd5a65",
      "4927af3c151244d1a5e61c64d76c64ac",
      "69208fcbcde048e3b949f2af1a23644a",
      "9d9f402593574ca49b2f3e226b59be2e",
      "62755a1f77654fdca6941bc43de6f61b",
      "b7a5c9f08e404d8ca70434b14e76aa20",
      "eb570e11287445038865e6fe476edaaa"
     ]
    },
    "id": "xMwiIR485FpP",
    "outputId": "6c16bcf1-564e-4725-d4a4-71b11fe822d4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3248c8911a3d44a28bc1d98615e223b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33934 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "i3a5qb6O__pA",
    "outputId": "008d4e95-5215-470c-b2cd-410e60193cfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \\n\\nখ্রিস্টপূর্ব ১<|eot_id|>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[100]['input_ids'])\n",
    "space = tokenizer(\" \", add_special_tokens=False).input_ids[0]\n",
    "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[100][\"labels\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fKuhvTRqA5SI",
    "outputId": "9eed8263-ae72-4046-b33c-ceba64395988"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 33,934 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.73 GiB of which 811.38 MiB is free. Process 74368 has 432.00 MiB memory in use. Process 74739 has 432.00 MiB memory in use. Process 312387 has 6.07 GiB memory in use. Process 74369 has 432.00 MiB memory in use. Process 2653758 has 7.58 GiB memory in use. Of the allocated memory 7.33 GiB is allocated by PyTorch, and 50.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:140\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m<string>:358\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3532\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3531\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3532\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3533\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3534\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_fp32\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:787\u001b[0m, in \u001b[0;36mconvert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_fp16_bf16_tensor\u001b[39m(tensor):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (is_torch_tensor(tensor) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    783\u001b[0m         torch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m    784\u001b[0m         torch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m    785\u001b[0m     )\n\u001b[0;32m--> 787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_to_fp32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_is_fp16_bf16_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:119\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    109\u001b[0m         data,\n\u001b[1;32m    110\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         ),\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[0;32m--> 119\u001b[0m         {\n\u001b[1;32m    120\u001b[0m             k: recursively_apply(\n\u001b[1;32m    121\u001b[0m                 func, v, \u001b[38;5;241m*\u001b[39margs, test_type\u001b[38;5;241m=\u001b[39mtest_type, error_on_other_type\u001b[38;5;241m=\u001b[39merror_on_other_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m         }\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:120\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    109\u001b[0m         data,\n\u001b[1;32m    110\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         ),\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    119\u001b[0m         {\n\u001b[0;32m--> 120\u001b[0m             k: \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m         }\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:127\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    119\u001b[0m         {\n\u001b[1;32m    120\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m         }\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:779\u001b[0m, in \u001b[0;36mconvert_to_fp32.<locals>._convert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_fp32\u001b[39m(tensor):\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.73 GiB of which 811.38 MiB is free. Process 74368 has 432.00 MiB memory in use. Process 74739 has 432.00 MiB memory in use. Process 312387 has 6.07 GiB memory in use. Process 74369 has 432.00 MiB memory in use. Process 2653758 has 7.58 GiB memory in use. Of the allocated memory 7.33 GiB is allocated by PyTorch, and 50.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5_qNMU5BY8B",
    "outputId": "1dd89f89-50b4-4c6a-c01d-05de009106e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=0.5222683399915695, metrics={'train_runtime': 326.8495, 'train_samples_per_second': 1.469, 'train_steps_per_second': 0.184, 'total_flos': 1.133758247061504e+16, 'train_loss': 0.5222683399915695, 'epoch': 0.014145105204219957})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct  1 16:14:40 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000               On  | 00000000:00:09.0 Off |                  Off |\n",
      "| 41%   35C    P8              14W / 140W |  15297MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_3LiXUgEW8A",
    "outputId": "9075cee6-7b00-47ca-ff56-1db4b75dc27c"
   },
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"ভারতের হরিয়ানা রাজ্যের পানিপথ গ্রামের নিকটে ১৫২৬ সালের ২১ এপ্রিল এই যুদ্ধ সংঘটিত হয়। ২০ শতকের আগে এই অঞ্চলে আরো কয়েকটি গুরুত্বপূর্ণ যুদ্ধ সংঘটিত হয়েছে। হিসাব অনুযায়ী বাবরের বাহিনীতে ১৫,০০০ সৈনিক এবং ২০ থেকে ২৪টি ফিল্ড আর্টি‌লারি ছিল। ইব্রাহিম বাহিনীতে সর্বমোট লোকসংখ্যা ছিল প্রায় ১,০০,০০০। তবে মূল লড়াইয়ের বাহিনীতে লোকসংখ্যা ছিল প্রায় ৩০,০০০ থেকে ৪০,০০০। এর পাশাপাশি যুদ্ধ হাতি ছিল প্রায় ১,০০০\"},\n",
    "    {\"role\": \"user\", \"content\": \"পানিপথের দ্বিতীয় যুদ্ধ কবে হয়েছিল?\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "ouputs = model.generate(\n",
    "    input_ids = inputs,\n",
    "    max_new_tokens = 64,\n",
    "    use_cache = True,\n",
    "    temperature = 0.01,\n",
    "    min_p = 0.1\n",
    ")\n",
    "\n",
    "tokenizer.batch_decode(ouputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "y8oRtf6EExgy",
    "outputId": "15d740f7-3aea-4ada-d917-81ee6532b7eb"
   },
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(ouputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arakEitwGQ7i",
    "outputId": "321750dc-dbdc-46a3-963a-c7ad665ac7fd"
   },
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"ভারতের হরিয়ানা রাজ্যের পানিপথ গ্রামের নিকটে ১৫২৬ সালের ২১ এপ্রিল এই যুদ্ধ সংঘটিত হয়। ২০ শতকের আগে এই অঞ্চলে আরো কয়েকটি গুরুত্বপূর্ণ যুদ্ধ সংঘটিত হয়েছে। হিসাব অনুযায়ী বাবরের বাহিনীতে ১৫,০০০ সৈনিক এবং ২০ থেকে ২৪টি ফিল্ড আর্টি‌লারি ছিল। ইব্রাহিম বাহিনীতে সর্বমোট লোকসংখ্যা ছিল প্রায় ১,০০,০০০। তবে মূল লড়াইয়ের বাহিনীতে লোকসংখ্যা ছিল প্রায় ৩০,০০০ থেকে ৪০,০০০। এর পাশাপাশি যুদ্ধ হাতি ছিল প্রায় ১,০০০\"},\n",
    "    {\"role\": \"user\", \"content\": \"ইব্রাহিম বাহিনীতে সর্ব মোট লোক সংখ্যা কত ছিল?\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "ouputs = model.generate(\n",
    "    input_ids = inputs,\n",
    "    max_new_tokens = 64,\n",
    "    use_cache = True,\n",
    "    temperature = 0.01,\n",
    "    min_p = 0.1\n",
    ")\n",
    "\n",
    "tokenizer.batch_decode(ouputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195,
     "referenced_widgets": [
      "b289a592963d403b856f91d364cc3ccd",
      "f40a69c1dfd6450faa177c6b67322217",
      "abc3c216a6e84131addf16d595217f0e",
      "3b44c040220245ab98efd504a25f6b4c",
      "eb34f0727ee04469a4ed7ea135870eeb",
      "f5fd2c12f98f41f58363951ed7e8bf86",
      "2ae3786682dd48cab478e69b0d5fc360",
      "4f2c59baf66a46f2bc8069d250cd6d23",
      "5300365bf44a4298b587a308dafd7510",
      "49cfbb0fcd8545babe515a8db5c55f9f",
      "4bdfa7c878cc4b22ba8105b56872249e",
      "f6a5b74b3231445d821e48b30e5cb9cc",
      "bf6aba0666d746ed9df59daa5e65d1ab",
      "9e91ae31847c4e0cb6309a58baa8bd54",
      "2f40a55f5ff64563af02ffd018c8b1ff",
      "f631290934dd4dea84410b6645e3aa5d",
      "1ba079db22fb4fecb6e63f3885650516",
      "0580a99c44e049caaeb843a5487d2bbc",
      "ea13b82eba6846efb37d79c756bb4d2b",
      "066254a7871642b9af25575af310c3e8",
      "d021502fd341475a92ded0cb82a1023f",
      "4f80c38079714d8785e0f8a727c86694",
      "2cc93067cf9d47b6b0f0952300d826e1",
      "6e71993b2e204c68998bc6a9fe98be7e",
      "b76d9f1d60ac4d5f8adc726216400914",
      "4a5bfa1df9424061a6a7f6dc6f154e2e",
      "d01d315ed0284be2b0ff5a1857b0b5bf",
      "223d4d14e90d40ec9afea424ab58b8d3",
      "1e20304265f04964bd4083b46e443cf1",
      "b36188742014450e9d63731871d36948",
      "d24e481f688e40aab74fcc80dabcf7d6",
      "915d9682a1604894aaf6f6873dd154c7",
      "05576bf15b964e3cb83fede7a733c8e3",
      "43d31737c5714b078913b689c3705a7d",
      "518664162ba4483db2fe42c20a31c3e5",
      "e373ac5b3d9548adad757b3345149d84",
      "7bab305b1d0a4176add5b3b1a176b6f7",
      "c47edab6dd6b4108ae90f56554c9fe4f",
      "1e70618d2c62426a8b47886a5a2028ad",
      "0945e6db75ae47368bf4b721008379fe",
      "57c12362ad34448581009bbff6b2d180",
      "33601d0f29ab4d598cc50b8d0414fb37",
      "92f88cb222734d329b74af7980fc4411",
      "f4e2ca50edb9413dae0c79e61f82ad84",
      "a13e18e51c6d48ab8d4a41f38c7bbf7e",
      "4c169a92c16e40f49d073d8246e2f126",
      "122d2de2784d466681c85e55cad5ca64",
      "b9ea34ab2e604772940d2f2fb73d60af",
      "c6e6b6ec3db846f8bf3a4e13a5c71214",
      "5da2a44b64444e629261cd011d1cfe3f",
      "95cf322c519642edb51f01e272f3a5ba",
      "236a3cbca6224ef19bfa2b5c8b568aae",
      "618401f55eec46ac98d50b610ed58978",
      "6625ee5f58404f08bbc627253cc4ed52",
      "c9d2f93806bd4dedab320d28ff19bc5d"
     ]
    },
    "id": "c6VO_fXpGhTK",
    "outputId": "61f7e2e5-4f30-4fa9-a54a-19924f6b9e72"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8975ca470194cabb73947dcd0cb4aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/97.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/Kowshik24/Bangla-llama-3.2-3B-Instruct-QA-v2\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"Bangla-llama-3.2-3B-Instruct-QA-v2\")\n",
    "tokenizer.save_pretrained(\"Bangla-llama-3.2-3B-Instruct-QA-v2\")\n",
    "\n",
    "# Save to Huggingface HUB\n",
    "\n",
    "model.push_to_hub(\"Kowshik24/Bangla-llama-3.2-3B-Instruct-QA-v2\",token=\"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\")\n",
    "tokenizer.push_to_hub(\"Kowshik24/Bangla-llama-3.2-3B-Instruct-QA-v2\",token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "69HhwoBQHXHC"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load validation data from Huggingface\n",
    "val_dataset = load_dataset('Kowshik24/BengaliQADataset', split='validation',token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VX01ExjJghL",
    "outputId": "c518f5eb-d432-4c3e-d8a7-18b84d977492"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'question', 'id', 'answers', 'answer_start', 'context'],\n",
       "    num_rows: 7488\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDjYT1OUJhf4",
    "outputId": "cc25e4c6-99ac-4629-c476-285021335964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7488"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ZvFYI3wQI94y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lowercase, trim, and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    import re\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    def remove_punctuation(text):\n",
    "        return re.sub(r'[^\\w\\s]', '', text)\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    return white_space_fix(remove_articles(remove_punctuation(lower(s))))\n",
    "\n",
    "def exact_match(prediction, ground_truth):\n",
    "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(pred_tokens) & Counter(truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = num_same / len(pred_tokens)\n",
    "    recall = num_same / len(truth_tokens)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "val_predictions = []\n",
    "ground_truth_values = []\n",
    "f1_scores = []\n",
    "em_scores = []\n",
    "\n",
    "def evaluate(dataset, model, tokenizer):\n",
    "\n",
    "    results = {\n",
    "        'query': [],\n",
    "        'prediction': [],\n",
    "        'ground_truth': [],\n",
    "        'f1_score': [],\n",
    "        'exact_match': []\n",
    "    }\n",
    "    total_em = 0\n",
    "    total_f1 = 0\n",
    "    n = len(dataset)\n",
    "\n",
    "    for example in dataset:\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "\n",
    "        # Handle the structure of ground truth answers\n",
    "        if isinstance(example['answers'], dict) and 'text' in example['answers']:\n",
    "            ground_truths = example['answers']['text']  # Ground truth answers should be a list\n",
    "        else:\n",
    "            # In case answers are a single string\n",
    "            ground_truths = [example['answers']]  # Convert to list for uniform handling\n",
    "\n",
    "        # Prepare input\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "\n",
    "        #print(\"Messages :\", messages)\n",
    "        \n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        #print(\"Inputs Shape:\", inputs.shape)\n",
    "        #print(\"Inputs:\", inputs)\n",
    "\n",
    "        # Generate prediction\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            max_new_tokens=64,\n",
    "            use_cache=True,\n",
    "            temperature=0.01,\n",
    "            min_p=0.1\n",
    "        )\n",
    "        #print(\"Full Prediction: \", tokenizer.batch_decode(ouputs))\n",
    "\n",
    "        # Decode the prediction\n",
    "        prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "        #print(\"Prediction: \", prediction.split(\"assistant\")[-1])\n",
    "        \n",
    "        val_predictions.append(prediction)\n",
    "\n",
    "        # Compute Exact Match and F1 for the best ground truth answer\n",
    "        em = max(exact_match(prediction.split(\"assistant\")[-1], truth) for truth in ground_truths)\n",
    "        f1 = max(f1_score(prediction.split(\"assistant\")[-1], truth) for truth in ground_truths)\n",
    "\n",
    "        #print(\"Exact Match: \", em)\n",
    "        #print(\"F1 score: \", f1)\n",
    "        #print(\"Ground Truth: \", ground_truths[0])\n",
    "\n",
    "        # Store the results\n",
    "        results['query'].append(question)\n",
    "        results['prediction'].append(prediction.split(\"assistant\")[-1])\n",
    "        results['ground_truth'].append(ground_truths[0])  # Storing the first ground truth for simplicity\n",
    "        results['f1_score'].append(f1)\n",
    "        results['exact_match'].append(em)\n",
    "\n",
    "        total_em += em\n",
    "        total_f1 += f1\n",
    "        \n",
    "\n",
    "    # Calculate average EM and F1\n",
    "    avg_em = total_em / n\n",
    "    avg_f1 = total_f1 / n\n",
    "    # Convert to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results , {\"Exact Match\": avg_em, \"F1 Score\": avg_f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72on35kBJqQM",
    "outputId": "4430012d-ec41-4e38-c332-972e8b5fa794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ['Charleston,_South_Carolina',\n",
       "  'Charleston,_South_Carolina',\n",
       "  'Charleston,_South_Carolina',\n",
       "  'Charleston,_South_Carolina',\n",
       "  'Charleston,_South_Carolina'],\n",
       " 'question': ['চার্লসটন, দক্ষিণ ক্যারোলিনা কোন কাউন্টিতে অবস্থিত?  ',\n",
       "  'চার্লসটন কোন বন্দরে অবস্থিত?  ',\n",
       "  'চার্লসটন হারবার কোন মহাসাগরের খাঁড়ি?  ',\n",
       "  'কোপার নদীর সাথে কোন নদী মিশে গিয়ে চার্লস্টন হারবার গঠন করে?  ',\n",
       "  'চার্লসটন কোন কাউন্টিতে অবস্থিত?  '],\n",
       " 'id': ['572e8700cb0c0d14000f1253',\n",
       "  '572e8700cb0c0d14000f1254',\n",
       "  '572e8700cb0c0d14000f1255',\n",
       "  '572e8700cb0c0d14000f1256',\n",
       "  '572ff8ff947a6a140053ceb5'],\n",
       " 'answers': ['চার্লসটন আমেরিকা য',\n",
       "  'চার্লসটন আমেরিকা য',\n",
       "  'আটলান্টিক মহাসাগরের ',\n",
       "  'অ্যাশলে এবং ক',\n",
       "  'চার্লসটন আমেরিকা য'],\n",
       " 'answer_start': [0, 0, 339, 294, 0],\n",
       " 'context': ['চার্লসটন আমেরিকা যুক্তরাষ্ট্রের দক্ষিণ ক্যারোলাইনা রাজ্যের প্রাচীনতম এবং দ্বিতীয় বৃহত্তম শহর, চার্লসটন কাউন্টির কাউন্টি আসন এবং চার্লসটন – নর্থ চার্লসটন – সামারভিলে মেট্রোপলিটন স্ট্যাটিস্টিকাল এরিয়ার প্রধান শহর  শহরটি দক্ষিণ ক্যারোলিনার উপকূলরেখার ভৌগলিক মিডপয়েন্টের ঠিক দক্ষিণে অবস্থিত এবং অ্যাশলে এবং কুপার নদীর নদীর সংগম দ্বারা গঠিত আটলান্টিক মহাসাগরের একটি খাঁটি চার্লস্টন হারবারে অবস্থিত, অথবা স্থানীয়ভাবে প্রকাশিত হয়েছে, \"যেখানে কুপার এবং অ্যাশলে রয়েছে। নদীগুলি একত্র হয়ে আটলান্টিক মহাসাগর গঠনে আসে। \"  ',\n",
       "  'চার্লসটন আমেরিকা যুক্তরাষ্ট্রের দক্ষিণ ক্যারোলাইনা রাজ্যের প্রাচীনতম এবং দ্বিতীয় বৃহত্তম শহর, চার্লসটন কাউন্টির কাউন্টি আসন এবং চার্লসটন – নর্থ চার্লসটন – সামারভিলে মেট্রোপলিটন স্ট্যাটিস্টিকাল এরিয়ার প্রধান শহর  শহরটি দক্ষিণ ক্যারোলিনার উপকূলরেখার ভৌগলিক মিডপয়েন্টের ঠিক দক্ষিণে অবস্থিত এবং অ্যাশলে এবং কুপার নদীর নদীর সংগম দ্বারা গঠিত আটলান্টিক মহাসাগরের একটি খাঁটি চার্লস্টন হারবারে অবস্থিত, অথবা স্থানীয়ভাবে প্রকাশিত হয়েছে, \"যেখানে কুপার এবং অ্যাশলে রয়েছে। নদীগুলি একত্র হয়ে আটলান্টিক মহাসাগর গঠনে আসে। \"  ',\n",
       "  'চার্লসটন আমেরিকা যুক্তরাষ্ট্রের দক্ষিণ ক্যারোলাইনা রাজ্যের প্রাচীনতম এবং দ্বিতীয় বৃহত্তম শহর, চার্লসটন কাউন্টির কাউন্টি আসন এবং চার্লসটন – নর্থ চার্লসটন – সামারভিলে মেট্রোপলিটন স্ট্যাটিস্টিকাল এরিয়ার প্রধান শহর  শহরটি দক্ষিণ ক্যারোলিনার উপকূলরেখার ভৌগলিক মিডপয়েন্টের ঠিক দক্ষিণে অবস্থিত এবং অ্যাশলে এবং কুপার নদীর নদীর সংগম দ্বারা গঠিত আটলান্টিক মহাসাগরের একটি খাঁটি চার্লস্টন হারবারে অবস্থিত, অথবা স্থানীয়ভাবে প্রকাশিত হয়েছে, \"যেখানে কুপার এবং অ্যাশলে রয়েছে। নদীগুলি একত্র হয়ে আটলান্টিক মহাসাগর গঠনে আসে। \"  ',\n",
       "  'চার্লসটন আমেরিকা যুক্তরাষ্ট্রের দক্ষিণ ক্যারোলাইনা রাজ্যের প্রাচীনতম এবং দ্বিতীয় বৃহত্তম শহর, চার্লসটন কাউন্টির কাউন্টি আসন এবং চার্লসটন – নর্থ চার্লসটন – সামারভিলে মেট্রোপলিটন স্ট্যাটিস্টিকাল এরিয়ার প্রধান শহর  শহরটি দক্ষিণ ক্যারোলিনার উপকূলরেখার ভৌগলিক মিডপয়েন্টের ঠিক দক্ষিণে অবস্থিত এবং অ্যাশলে এবং কুপার নদীর নদীর সংগম দ্বারা গঠিত আটলান্টিক মহাসাগরের একটি খাঁটি চার্লস্টন হারবারে অবস্থিত, অথবা স্থানীয়ভাবে প্রকাশিত হয়েছে, \"যেখানে কুপার এবং অ্যাশলে রয়েছে। নদীগুলি একত্র হয়ে আটলান্টিক মহাসাগর গঠনে আসে। \"  ',\n",
       "  'চার্লসটন আমেরিকা যুক্তরাষ্ট্রের দক্ষিণ ক্যারোলাইনা রাজ্যের প্রাচীনতম এবং দ্বিতীয় বৃহত্তম শহর, চার্লসটন কাউন্টির কাউন্টি আসন এবং চার্লসটন – নর্থ চার্লসটন – সামারভিলে মেট্রোপলিটন স্ট্যাটিস্টিকাল এরিয়ার প্রধান শহর  শহরটি দক্ষিণ ক্যারোলিনার উপকূলরেখার ভৌগলিক মিডপয়েন্টের ঠিক দক্ষিণে অবস্থিত এবং অ্যাশলে এবং কুপার নদীর নদীর সংগম দ্বারা গঠিত আটলান্টিক মহাসাগরের একটি খাঁটি চার্লস্টন হারবারে অবস্থিত, অথবা স্থানীয়ভাবে প্রকাশিত হয়েছে, \"যেখানে কুপার এবং অ্যাশলে রয়েছে। নদীগুলি একত্র হয়ে আটলান্টিক মহাসাগর গঠনে আসে। \"  ']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "L8pA5ZHiI_qS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 14.22%\n",
      "F1 Score: 38.63%\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "# Initialize the tokenizer and model (adjust as needed)\n",
    "tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Evaluate on the validation data\n",
    "df_results, results = evaluate(val_dataset, model, tokenizer)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Exact Match: {results['Exact Match']*100:.2f}%\")\n",
    "print(f\"F1 Score: {results['F1 Score']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>চার্লসটন, দক্ষিণ ক্যারোলিনা কোন কাউন্টিতে অবস্...</td>\n",
       "      <td>\\n\\nচার্লসটন কাউন্টির কাউন্টি আসন এ</td>\n",
       "      <td>চার্লসটন আমেরিকা য</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>চার্লসটন কোন বন্দরে অবস্থিত?</td>\n",
       "      <td>\\n\\nচার্লসটন হারবারে</td>\n",
       "      <td>চার্লসটন আমেরিকা য</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>চার্লসটন হারবার কোন মহাসাগরের খাঁড়ি?</td>\n",
       "      <td>\\n\\nআটলান্টিক মহাসাগরের</td>\n",
       "      <td>আটলান্টিক মহাসাগরের</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>কোপার নদীর সাথে কোন নদী মিশে গিয়ে চার্লস্টন হ...</td>\n",
       "      <td>\\n\\nঅ্যাশলে এ</td>\n",
       "      <td>অ্যাশলে এবং ক</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>চার্লসটন কোন কাউন্টিতে অবস্থিত?</td>\n",
       "      <td>\\n\\nচার্লসটন কাউন্টির কাউন্টি আসন এ</td>\n",
       "      <td>চার্লসটন আমেরিকা য</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  চার্লসটন, দক্ষিণ ক্যারোলিনা কোন কাউন্টিতে অবস্...   \n",
       "1                     চার্লসটন কোন বন্দরে অবস্থিত?     \n",
       "2            চার্লসটন হারবার কোন মহাসাগরের খাঁড়ি?     \n",
       "3  কোপার নদীর সাথে কোন নদী মিশে গিয়ে চার্লস্টন হ...   \n",
       "4                  চার্লসটন কোন কাউন্টিতে অবস্থিত?     \n",
       "\n",
       "                            prediction          ground_truth  f1_score  \\\n",
       "0  \\n\\nচার্লসটন কাউন্টির কাউন্টি আসন এ    চার্লসটন আমেরিকা য      0.25   \n",
       "1                 \\n\\nচার্লসটন হারবারে    চার্লসটন আমেরিকা য      0.40   \n",
       "2              \\n\\nআটলান্টিক মহাসাগরের  আটলান্টিক মহাসাগরের       1.00   \n",
       "3                        \\n\\nঅ্যাশলে এ         অ্যাশলে এবং ক      0.40   \n",
       "4  \\n\\nচার্লসটন কাউন্টির কাউন্টি আসন এ    চার্লসটন আমেরিকা য      0.25   \n",
       "\n",
       "   exact_match  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"/workspace/test/results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtjlkXYDJH0q"
   },
   "outputs": [],
   "source": [
    "print(val_dataset[0])  # Check the structure of the first example\n",
    "def evaluate(dataset, model, tokenizer):\n",
    "    total_em = 0\n",
    "    total_f1 = 0\n",
    "    n = len(dataset)\n",
    "\n",
    "    for example in dataset:\n",
    "        # Adjust access to context and question based on the real structure\n",
    "        # Assuming 'example' is a dictionary with 'context', 'question', and 'answers' keys.\n",
    "        if isinstance(example, dict):\n",
    "            context = example.get('context', '')\n",
    "            question = example.get('question', '')\n",
    "            answers = example.get('answers', '')\n",
    "\n",
    "            # If answers is a dictionary, handle accordingly\n",
    "            if isinstance(answers, dict) and 'text' in answers:\n",
    "                ground_truths = answers['text']  # Ground truth answers should be a list\n",
    "            else:\n",
    "                ground_truths = [answers]  # Convert to list for uniform handling\n",
    "\n",
    "            # Prepare input\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": context},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ]\n",
    "            inputs = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(\"cuda\")\n",
    "\n",
    "            # Generate prediction\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs,\n",
    "                max_new_tokens=64,\n",
    "                use_cache=True,\n",
    "                temperature=0.01,\n",
    "                min_p=0.1\n",
    "            )\n",
    "\n",
    "            # Decode the prediction\n",
    "            prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "            # Compute Exact Match and F1 for the best ground truth answer\n",
    "            em = max(exact_match(prediction, truth) for truth in ground_truths)\n",
    "            f1 = max(f1_score(prediction, truth) for truth in ground_truths)\n",
    "\n",
    "            total_em += em\n",
    "            total_f1 += f1\n",
    "\n",
    "    # Calculate average EM and F1\n",
    "    avg_em = total_em / n\n",
    "    avg_f1 = total_f1 / n\n",
    "\n",
    "    return {\"Exact Match\": avg_em, \"F1 Score\": avg_f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepeval\n",
      "  Downloading deepeval-1.3.2-py3-none-any.whl.metadata (977 bytes)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepeval) (4.66.5)\n",
      "Collecting pytest (from deepeval)\n",
      "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting tabulate (from deepeval)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting typer (from deepeval)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from deepeval) (13.8.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from deepeval) (3.20.3)\n",
      "Collecting pydantic (from deepeval)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk (from deepeval)\n",
      "  Downloading sentry_sdk-2.15.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting pytest-repeat (from deepeval)\n",
      "  Downloading pytest_repeat-0.9.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pytest-xdist (from deepeval)\n",
      "  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting portalocker (from deepeval)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain (from deepeval)\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core (from deepeval)\n",
      "  Downloading langchain_core-0.3.7-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-openai (from deepeval)\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ragas (from deepeval)\n",
      "  Downloading ragas-0.1.20-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting docx2txt~=0.8 (from deepeval)\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-metadata>=6.0.2 (from deepeval)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tenacity~=8.4.1 (from deepeval)\n",
      "  Downloading tenacity-8.4.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opentelemetry-api~=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-sdk~=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc~=1.24.0 (from deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpcio~=1.63.0 (from deepeval)\n",
      "  Downloading grpcio-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.0.2->deepeval)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api~=1.24.0->deepeval)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata>=6.0.2 (from deepeval)\n",
      "  Downloading importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=6.0.2->deepeval) (1.0.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk~=1.24.0->deepeval)\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk~=1.24.0->deepeval) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->deepeval)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (3.10.6)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (4.0.3)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain->deepeval)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain->deepeval)\n",
      "  Downloading langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->deepeval) (1.24.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core->deepeval)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core->deepeval) (23.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->deepeval)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic->deepeval)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->deepeval) (2022.12.7)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai->deepeval)\n",
      "  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai->deepeval)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting iniconfig (from pytest->deepeval)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->deepeval)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval) (1.1.3)\n",
      "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->deepeval) (2.0.1)\n",
      "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\n",
      "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval) (3.0.1)\n",
      "INFO: pip is looking at multiple versions of ragas to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ragas (from deepeval)\n",
      "  Downloading ragas-0.1.19-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting langchain-community (from ragas->deepeval)\n",
      "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pysbd>=0.3.4 (from ragas->deepeval)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas->deepeval) (1.5.8)\n",
      "Collecting appdirs (from ragas->deepeval)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->deepeval) (2.16.1)\n",
      "Collecting click>=8.0.0 (from typer->deepeval)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer->deepeval)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.13.1)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api~=1.24.0->deepeval)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (2.4)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain->deepeval)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain->deepeval)\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai->deepeval) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai->deepeval) (1.7.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai->deepeval)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai->deepeval) (1.3.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain->deepeval)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval) (2024.9.11)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->ragas->deepeval) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas->deepeval) (0.25.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->ragas->deepeval)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->ragas->deepeval)\n",
      "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas->deepeval) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas->deepeval) (1.16.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading deepeval-1.3.2-py3-none-any.whl (384 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.1/384.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Downloading tenacity-8.4.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.7-py3-none-any.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.3/342.3 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\n",
      "Downloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ragas-0.1.19-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.15.0-py2.py3-none-any.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.129-py3-none-any.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.50.2-py3-none-any.whl (382 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=2ca003f8627e9a45c17fadbfbe7bf53b2ca739ea73d5aa87f368d1d9937a828d\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt, appdirs, wrapt, tenacity, tabulate, shellingham, sentry-sdk, python-dotenv, pysbd, pydantic-core, portalocker, pluggy, orjson, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, marshmallow, jsonpatch, jiter, iniconfig, importlib-metadata, h11, grpcio, greenlet, googleapis-common-protos, execnet, click, annotated-types, typing-inspect, tiktoken, SQLAlchemy, pytest, pydantic, opentelemetry-exporter-otlp-proto-common, httpcore, deprecated, typer, pytest-xdist, pytest-repeat, pydantic-settings, opentelemetry-api, httpx, dataclasses-json, opentelemetry-sdk, openai, langsmith, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community, ragas, deepeval\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.6.4\n",
      "    Uninstalling importlib-metadata-4.6.4:\n",
      "      Successfully uninstalled importlib-metadata-4.6.4\n",
      "Successfully installed SQLAlchemy-2.0.35 annotated-types-0.7.0 appdirs-1.4.4 click-8.1.7 dataclasses-json-0.6.7 deepeval-1.3.2 deprecated-1.2.14 docx2txt-0.8 execnet-2.1.1 googleapis-common-protos-1.65.0 greenlet-3.1.1 grpcio-1.63.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 importlib-metadata-7.0.0 iniconfig-2.0.0 jiter-0.5.0 jsonpatch-1.33 langchain-0.3.1 langchain-community-0.3.1 langchain-core-0.3.7 langchain-openai-0.2.1 langchain-text-splitters-0.3.0 langsmith-0.1.129 marshmallow-3.22.0 mypy-extensions-1.0.0 openai-1.50.2 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 orjson-3.10.7 pluggy-1.5.0 portalocker-2.10.1 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.5.2 pysbd-0.3.4 pytest-8.3.3 pytest-repeat-0.9.3 pytest-xdist-3.6.1 python-dotenv-1.0.1 ragas-0.1.19 sentry-sdk-2.15.0 shellingham-1.5.4 tabulate-0.9.0 tenacity-8.4.2 tiktoken-0.7.0 typer-0.12.5 typing-inspect-0.9.0 wrapt-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m134.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.00\n",
      "Exact Match Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = \"/workspace/test/results.csv\"  # Update with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate F1 Score and Exact Match\n",
    "# For exact match, we will check if the predicted response matches the ground truth exactly.\n",
    "exact_matches = df['prediction'] == df['ground_truth']\n",
    "exact_match_score = accuracy_score(exact_matches, [True] * len(exact_matches))\n",
    "\n",
    "# For F1 Score, we need to convert the responses into binary format\n",
    "# Here we assume that any non-empty response is considered a positive prediction.\n",
    "y_true = df['ground_truth'].apply(lambda x: 1 if x else 0)\n",
    "y_pred = df['prediction'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Exact Match Score: {exact_match_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05576bf15b964e3cb83fede7a733c8e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0580a99c44e049caaeb843a5487d2bbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "066254a7871642b9af25575af310c3e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0945e6db75ae47368bf4b721008379fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c284ff2943f419eb1623787468562b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "122d2de2784d466681c85e55cad5ca64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_236a3cbca6224ef19bfa2b5c8b568aae",
      "max": 17209920,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_618401f55eec46ac98d50b610ed58978",
      "value": 17209920
     }
    },
    "131ab9d6182842b4b87c9c0f39b51783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a83ebed2dff43359f3ee83f2cd779c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ba079db22fb4fecb6e63f3885650516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e20304265f04964bd4083b46e443cf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e70618d2c62426a8b47886a5a2028ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "223d4d14e90d40ec9afea424ab58b8d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "236a3cbca6224ef19bfa2b5c8b568aae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2901416e9d334ad7abc98d5c244a7dc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dcb4aae63be44868b3f7b59303fd010",
      "placeholder": "​",
      "style": "IPY_MODEL_131ab9d6182842b4b87c9c0f39b51783",
      "value": "Map (num_proc=2): 100%"
     }
    },
    "2ae3786682dd48cab478e69b0d5fc360": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cc93067cf9d47b6b0f0952300d826e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e71993b2e204c68998bc6a9fe98be7e",
       "IPY_MODEL_b76d9f1d60ac4d5f8adc726216400914",
       "IPY_MODEL_4a5bfa1df9424061a6a7f6dc6f154e2e"
      ],
      "layout": "IPY_MODEL_d01d315ed0284be2b0ff5a1857b0b5bf"
     }
    },
    "2f40a55f5ff64563af02ffd018c8b1ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d021502fd341475a92ded0cb82a1023f",
      "placeholder": "​",
      "style": "IPY_MODEL_4f80c38079714d8785e0f8a727c86694",
      "value": " 1/1 [00:01&lt;00:00,  1.60s/it]"
     }
    },
    "33601d0f29ab4d598cc50b8d0414fb37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b44c040220245ab98efd504a25f6b4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49cfbb0fcd8545babe515a8db5c55f9f",
      "placeholder": "​",
      "style": "IPY_MODEL_4bdfa7c878cc4b22ba8105b56872249e",
      "value": " 598/598 [00:00&lt;00:00, 12.5kB/s]"
     }
    },
    "3dcb4aae63be44868b3f7b59303fd010": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41a5d13a96404f9da1cb1ff488d8be46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43d31737c5714b078913b689c3705a7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_518664162ba4483db2fe42c20a31c3e5",
       "IPY_MODEL_e373ac5b3d9548adad757b3345149d84",
       "IPY_MODEL_7bab305b1d0a4176add5b3b1a176b6f7"
      ],
      "layout": "IPY_MODEL_c47edab6dd6b4108ae90f56554c9fe4f"
     }
    },
    "470c597e44e34e86900d1e7fb95c0993": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4927af3c151244d1a5e61c64d76c64ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49cfbb0fcd8545babe515a8db5c55f9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a5bfa1df9424061a6a7f6dc6f154e2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_915d9682a1604894aaf6f6873dd154c7",
      "placeholder": "​",
      "style": "IPY_MODEL_05576bf15b964e3cb83fede7a733c8e3",
      "value": " 112M/? [00:01&lt;00:00, 114MB/s]"
     }
    },
    "4bdfa7c878cc4b22ba8105b56872249e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c169a92c16e40f49d073d8246e2f126": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5da2a44b64444e629261cd011d1cfe3f",
      "placeholder": "​",
      "style": "IPY_MODEL_95cf322c519642edb51f01e272f3a5ba",
      "value": "tokenizer.json: "
     }
    },
    "4cc30070c3e84ba199cf070c518cdffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2901416e9d334ad7abc98d5c244a7dc2",
       "IPY_MODEL_8e513ff19cf446eba8192f2d0b818048",
       "IPY_MODEL_c02b81fd46684181bd212cf2d46e5996"
      ],
      "layout": "IPY_MODEL_f75e14902a114ab288b7574155877de7"
     }
    },
    "4f2c59baf66a46f2bc8069d250cd6d23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f80c38079714d8785e0f8a727c86694": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "518664162ba4483db2fe42c20a31c3e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e70618d2c62426a8b47886a5a2028ad",
      "placeholder": "​",
      "style": "IPY_MODEL_0945e6db75ae47368bf4b721008379fe",
      "value": "100%"
     }
    },
    "5300365bf44a4298b587a308dafd7510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53e73fb7d3ee4e8abe14d30a8592f18c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7945a68885804cda87a9fd0319937f7f",
      "max": 33934,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c284ff2943f419eb1623787468562b0",
      "value": 33934
     }
    },
    "55f8d3afa5c74ce0aa1a3b2d331123b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7a5c9f08e404d8ca70434b14e76aa20",
      "placeholder": "​",
      "style": "IPY_MODEL_eb570e11287445038865e6fe476edaaa",
      "value": " 33934/33934 [01:10&lt;00:00, 510.76 examples/s]"
     }
    },
    "57c12362ad34448581009bbff6b2d180": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58d30f2eda5a44f8ad7e4deaae03fb07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbf2d665f79c48b3bf1e13776764d7c9",
      "placeholder": "​",
      "style": "IPY_MODEL_87d6126facf840daaf58d8e4c36ad575",
      "value": "Map: 100%"
     }
    },
    "5da2a44b64444e629261cd011d1cfe3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "618401f55eec46ac98d50b610ed58978": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "62755a1f77654fdca6941bc43de6f61b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6625ee5f58404f08bbc627253cc4ed52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69208fcbcde048e3b949f2af1a23644a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e71993b2e204c68998bc6a9fe98be7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_223d4d14e90d40ec9afea424ab58b8d3",
      "placeholder": "​",
      "style": "IPY_MODEL_1e20304265f04964bd4083b46e443cf1",
      "value": "adapter_model.safetensors: "
     }
    },
    "7945a68885804cda87a9fd0319937f7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b43c37118d5467dbd3e6f799af413b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bab305b1d0a4176add5b3b1a176b6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92f88cb222734d329b74af7980fc4411",
      "placeholder": "​",
      "style": "IPY_MODEL_f4e2ca50edb9413dae0c79e61f82ad84",
      "value": " 1/1 [00:01&lt;00:00,  1.12s/it]"
     }
    },
    "7cdcb2f62d1046aba0d4faa537cd5a65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87d6126facf840daaf58d8e4c36ad575": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8dd0ec32d90840718ecad72dc8b5985c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e513ff19cf446eba8192f2d0b818048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8dd0ec32d90840718ecad72dc8b5985c",
      "max": 33934,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_470c597e44e34e86900d1e7fb95c0993",
      "value": 33934
     }
    },
    "915d9682a1604894aaf6f6873dd154c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92f88cb222734d329b74af7980fc4411": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95cf322c519642edb51f01e272f3a5ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c62889c16864a338d1689561d41a1a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58d30f2eda5a44f8ad7e4deaae03fb07",
       "IPY_MODEL_53e73fb7d3ee4e8abe14d30a8592f18c",
       "IPY_MODEL_c8e44a505fa34497a9cb289c8da14b90"
      ],
      "layout": "IPY_MODEL_1a83ebed2dff43359f3ee83f2cd779c5"
     }
    },
    "9d9f402593574ca49b2f3e226b59be2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e91ae31847c4e0cb6309a58baa8bd54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea13b82eba6846efb37d79c756bb4d2b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_066254a7871642b9af25575af310c3e8",
      "value": 1
     }
    },
    "a13e18e51c6d48ab8d4a41f38c7bbf7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c169a92c16e40f49d073d8246e2f126",
       "IPY_MODEL_122d2de2784d466681c85e55cad5ca64",
       "IPY_MODEL_b9ea34ab2e604772940d2f2fb73d60af"
      ],
      "layout": "IPY_MODEL_c6e6b6ec3db846f8bf3a4e13a5c71214"
     }
    },
    "abc3c216a6e84131addf16d595217f0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f2c59baf66a46f2bc8069d250cd6d23",
      "max": 598,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5300365bf44a4298b587a308dafd7510",
      "value": 598
     }
    },
    "b289a592963d403b856f91d364cc3ccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f40a69c1dfd6450faa177c6b67322217",
       "IPY_MODEL_abc3c216a6e84131addf16d595217f0e",
       "IPY_MODEL_3b44c040220245ab98efd504a25f6b4c"
      ],
      "layout": "IPY_MODEL_eb34f0727ee04469a4ed7ea135870eeb"
     }
    },
    "b36188742014450e9d63731871d36948": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b76d9f1d60ac4d5f8adc726216400914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b36188742014450e9d63731871d36948",
      "max": 97307544,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d24e481f688e40aab74fcc80dabcf7d6",
      "value": 97307544
     }
    },
    "b79fa1195b45447f94c97b151b2f8df1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4927af3c151244d1a5e61c64d76c64ac",
      "placeholder": "​",
      "style": "IPY_MODEL_69208fcbcde048e3b949f2af1a23644a",
      "value": "Map: 100%"
     }
    },
    "b7a5c9f08e404d8ca70434b14e76aa20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9ea34ab2e604772940d2f2fb73d60af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6625ee5f58404f08bbc627253cc4ed52",
      "placeholder": "​",
      "style": "IPY_MODEL_c9d2f93806bd4dedab320d28ff19bc5d",
      "value": " 32.0M/? [00:00&lt;00:00, 42.0MB/s]"
     }
    },
    "bf6aba0666d746ed9df59daa5e65d1ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ba079db22fb4fecb6e63f3885650516",
      "placeholder": "​",
      "style": "IPY_MODEL_0580a99c44e049caaeb843a5487d2bbc",
      "value": "100%"
     }
    },
    "c02b81fd46684181bd212cf2d46e5996": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd1c18bbcd5949d89f58c88ec8b409cd",
      "placeholder": "​",
      "style": "IPY_MODEL_41a5d13a96404f9da1cb1ff488d8be46",
      "value": " 33934/33934 [01:15&lt;00:00, 524.39 examples/s]"
     }
    },
    "c47edab6dd6b4108ae90f56554c9fe4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e6b6ec3db846f8bf3a4e13a5c71214": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8e44a505fa34497a9cb289c8da14b90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de286e54e62a45949f6b2cf8b4e659b6",
      "placeholder": "​",
      "style": "IPY_MODEL_7b43c37118d5467dbd3e6f799af413b5",
      "value": " 33934/33934 [00:00&lt;00:00, 37889.45 examples/s]"
     }
    },
    "c9d2f93806bd4dedab320d28ff19bc5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd1c18bbcd5949d89f58c88ec8b409cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d01d315ed0284be2b0ff5a1857b0b5bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d021502fd341475a92ded0cb82a1023f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d24e481f688e40aab74fcc80dabcf7d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d57a0987bdd94067b85d32feaed7902c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d9f402593574ca49b2f3e226b59be2e",
      "max": 33934,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62755a1f77654fdca6941bc43de6f61b",
      "value": 33934
     }
    },
    "d93543ad8e2f46409e452556e5dfc1b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b79fa1195b45447f94c97b151b2f8df1",
       "IPY_MODEL_d57a0987bdd94067b85d32feaed7902c",
       "IPY_MODEL_55f8d3afa5c74ce0aa1a3b2d331123b7"
      ],
      "layout": "IPY_MODEL_7cdcb2f62d1046aba0d4faa537cd5a65"
     }
    },
    "de286e54e62a45949f6b2cf8b4e659b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e373ac5b3d9548adad757b3345149d84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57c12362ad34448581009bbff6b2d180",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33601d0f29ab4d598cc50b8d0414fb37",
      "value": 1
     }
    },
    "ea13b82eba6846efb37d79c756bb4d2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb34f0727ee04469a4ed7ea135870eeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb570e11287445038865e6fe476edaaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f40a69c1dfd6450faa177c6b67322217": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5fd2c12f98f41f58363951ed7e8bf86",
      "placeholder": "​",
      "style": "IPY_MODEL_2ae3786682dd48cab478e69b0d5fc360",
      "value": "README.md: 100%"
     }
    },
    "f4e2ca50edb9413dae0c79e61f82ad84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5fd2c12f98f41f58363951ed7e8bf86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f631290934dd4dea84410b6645e3aa5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6a5b74b3231445d821e48b30e5cb9cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf6aba0666d746ed9df59daa5e65d1ab",
       "IPY_MODEL_9e91ae31847c4e0cb6309a58baa8bd54",
       "IPY_MODEL_2f40a55f5ff64563af02ffd018c8b1ff"
      ],
      "layout": "IPY_MODEL_f631290934dd4dea84410b6645e3aa5d"
     }
    },
    "f75e14902a114ab288b7574155877de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbf2d665f79c48b3bf1e13776764d7c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
